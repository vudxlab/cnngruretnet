"""
Script v·∫Ω bi·ªÉu ƒë·ªì so s√°nh predictions gi·ªØa c√°c models v√† output_steps
"""

import os
import sys
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import pickle


def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description="V·∫Ω bi·ªÉu ƒë·ªì so s√°nh predictions"
    )
    parser.add_argument(
        '--results_dir',
        type=str,
        default='results',
        help='Th∆∞ m·ª•c ch·ª©a k·∫øt qu·∫£ (default: results/)'
    )
    parser.add_argument(
        '--output_dir',
        type=str,
        default='analysis',
        help='Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ (default: analysis/)'
    )
    parser.add_argument(
        '--num_samples',
        type=int,
        default=5,
        help='S·ªë samples ƒë·ªÉ v·∫Ω (default: 5)'
    )
    return parser.parse_args()


def load_test_data_and_predictions(results_dir, output_step, model):
    """
    Load test data v√† predictions t·ª´ folder k·∫øt qu·∫£

    Args:
        results_dir: Th∆∞ m·ª•c ch·ª©a k·∫øt qu·∫£
        output_step: Output step
        model: T√™n model

    Returns:
        tuple: (X_test, y_test, y_pred, scaler_values) ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
    """
    model_path = os.path.join(results_dir, str(output_step), model)

    # Ki·ªÉm tra folder t·ªìn t·∫°i
    if not os.path.exists(model_path):
        return None

    try:
        # Load scaler
        scaler_path = os.path.join(model_path, 'scaler_values.npy')
        if os.path.exists(scaler_path):
            scaler_values = np.load(scaler_path, allow_pickle=True).item()
        else:
            scaler_values = None

        # C·∫ßn load model v√† predict l·∫°i v√¨ kh√¥ng l∆∞u predictions
        # Ho·∫∑c c√≥ th·ªÉ load t·ª´ predictions folder n·∫øu c√≥
        predictions_folder = os.path.join(model_path, 'predictions')

        if not os.path.exists(predictions_folder):
            print(f"  ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y predictions folder: {model}/{output_step}")
            return None

        # T√¨m c√°c file numpy trong predictions folder (n·∫øu c√≥)
        # Th√¥ng th∆∞·ªùng predictions ƒë∆∞·ª£c l∆∞u trong folder n√†y
        # Nh∆∞ng c·∫ßn re-generate t·ª´ model n·∫øu ch∆∞a c√≥

        return None  # Placeholder, c·∫ßn implement load predictions

    except Exception as e:
        print(f"  ‚ùå L·ªói khi load data: {e}")
        return None


def regenerate_predictions(results_dir, output_step, model):
    """
    Re-generate predictions t·ª´ saved model

    Args:
        results_dir: Th∆∞ m·ª•c ch·ª©a k·∫øt qu·∫£
        output_step: Output step
        model: T√™n model

    Returns:
        tuple: (y_true, y_pred) ho·∫∑c None
    """
    import tensorflow as tf
    from data_cache import DataCache
    from config import Config

    model_path = os.path.join(results_dir, str(output_step), model)

    try:
        # Load model
        model_file = os.path.join(model_path, 'model_saved.keras')
        if not os.path.exists(model_file):
            return None

        keras_model = tf.keras.models.load_model(model_file)

        # Load data from cache
        cache = DataCache()
        cache_key = cache.get_cache_key(
            sensor_idx=0,  # Assume sensor 0
            output_steps=output_step,
            add_noise=True,  # Assume with noise
            input_steps=50
        )

        if not cache.cache_exists(cache_key):
            print(f"  ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y cache cho output_step={output_step}")
            return None

        data_dict = cache.load_cache(cache_key)

        # Get test data
        X_test = data_dict['X_test']
        y_test = data_dict['y_test']
        preprocessor = data_dict['preprocessor']

        # Predict
        y_pred_scaled = keras_model.predict(X_test[:10], verbose=0)

        # Denormalize
        y_true = preprocessor.inverse_transform(y_test[:10])
        y_pred = preprocessor.inverse_transform(y_pred_scaled)

        return y_true, y_pred

    except Exception as e:
        print(f"  ‚ùå L·ªói regenerate predictions: {e}")
        return None


def regenerate_predictions_full(results_dir, output_step, model):
    """
    Re-generate predictions t·ª´ saved model cho TO√ÄN B·ªò test set

    Args:
        results_dir: Th∆∞ m·ª•c ch·ª©a k·∫øt qu·∫£
        output_step: Output step
        model: T√™n model

    Returns:
        tuple: (y_true, y_pred) to√†n b·ªô test set ho·∫∑c None
    """
    import tensorflow as tf
    from data_cache import DataCache
    from config import Config
    from data_loader import VibrationDataLoader
    from data_preprocessing import DataPreprocessor

    model_path = os.path.join(results_dir, str(output_step), model)

    try:
        # Load model
        model_file = os.path.join(model_path, 'model_saved.keras')
        if not os.path.exists(model_file):
            return None

        keras_model = tf.keras.models.load_model(model_file)

        # Load data from cache ho·∫∑c t·∫°o m·ªõi
        cache = DataCache()
        cache_key = cache.get_cache_key(
            sensor_idx=0,
            output_steps=output_step,
            add_noise=True,
            input_steps=50
        )

        if cache.cache_exists(cache_key):
            data_dict = cache.load_cache(cache_key)
        else:
            # T·∫°o cache m·ªõi
            mat_file = Config.get_mat_file_path()
            data_loader = VibrationDataLoader(mat_file)
            full_data = data_loader.load_mat_file()
            raw_data = data_loader.get_sensor_data(sensor_idx=0)

            preprocessor = DataPreprocessor(
                input_steps=50,
                output_steps=output_step,
                add_noise=True
            )

            data_dict = preprocessor.prepare_data(raw_data)
            cache.save_cache(data_dict, cache_key)

        # Get TO√ÄN B·ªò test data
        X_test = data_dict['X_test']
        y_test = data_dict['y_test']
        preprocessor = data_dict['preprocessor']

        # Predict to√†n b·ªô
        y_pred_scaled = keras_model.predict(X_test, verbose=0)

        # Denormalize
        y_true = preprocessor.inverse_transform(y_test)
        y_pred = preprocessor.inverse_transform(y_pred_scaled)

        return y_true, y_pred

    except Exception as e:
        print(f"  ‚ùå L·ªói regenerate full predictions: {e}")
        return None


def plot_comparison_by_output_step(results_dir, output_step, models, output_dir, num_samples=3):
    """
    V·∫Ω bi·ªÉu ƒë·ªì so s√°nh predictions c·ªßa c√°c models cho c√πng output_step

    Args:
        results_dir: Th∆∞ m·ª•c k·∫øt qu·∫£
        output_step: Output step c·∫ßn so s√°nh
        models: Danh s√°ch models
        output_dir: Th∆∞ m·ª•c output
        num_samples: S·ªë samples ƒë·ªÉ v·∫Ω
    """
    print(f"\nüìä ƒêang v·∫Ω comparison cho output_step={output_step}...")

    # Load predictions cho t·∫•t c·∫£ models
    predictions_data = {}

    for model in models:
        result = regenerate_predictions(results_dir, output_step, model)
        if result is not None:
            y_true, y_pred = result
            predictions_data[model] = {
                'y_true': y_true,
                'y_pred': y_pred
            }
            print(f"  ‚úì Loaded {model}")

    if not predictions_data:
        print(f"  ‚ö†Ô∏è  Kh√¥ng c√≥ predictions cho output_step={output_step}")
        return

    # V·∫Ω bi·ªÉu ƒë·ªì
    num_models = len(predictions_data)
    fig, axes = plt.subplots(num_samples, num_models, figsize=(5*num_models, 3*num_samples))

    if num_samples == 1:
        axes = axes.reshape(1, -1)
    if num_models == 1:
        axes = axes.reshape(-1, 1)

    colors = {'conv1d_gru': '#2ecc71', 'gru': '#3498db', 'conv1d': '#e74c3c'}
    model_names = {'conv1d_gru': 'Conv1D-GRU-ResNet', 'gru': 'GRU', 'conv1d': 'Conv1D'}

    # Get y_true (same for all models)
    y_true_ref = list(predictions_data.values())[0]['y_true']

    for sample_idx in range(num_samples):
        for model_idx, (model, data) in enumerate(predictions_data.items()):
            ax = axes[sample_idx, model_idx]

            y_true_sample = data['y_true'][sample_idx]
            y_pred_sample = data['y_pred'][sample_idx]

            # Plot
            time_steps = range(len(y_true_sample))

            ax.plot(time_steps, y_true_sample, 'o-', linewidth=2, markersize=6,
                   label='True', color='black', alpha=0.7)
            ax.plot(time_steps, y_pred_sample, 's-', linewidth=2, markersize=6,
                   label='Predicted', color=colors.get(model, '#95a5a6'))

            # Calculate error
            mae = np.mean(np.abs(y_true_sample - y_pred_sample))

            model_display_name = model_names.get(model, model.upper().replace("_", "-"))
            ax.set_title(f'{model_display_name}\nSample {sample_idx+1} (MAE={mae:.6f})',
                        fontsize=11, fontweight='bold')
            ax.set_xlabel('Timestep', fontsize=10)
            ax.set_ylabel('Value', fontsize=10)
            ax.legend(fontsize=9, loc='best')
            ax.grid(True, alpha=0.3, linestyle='--')

    plt.suptitle(f'Prediction Comparison - Output Steps = {output_step}',
                fontsize=14, fontweight='bold', y=1.00)
    plt.tight_layout()

    # Save
    os.makedirs(os.path.join(output_dir, 'predictions_comparison'), exist_ok=True)
    output_file = os.path.join(output_dir, 'predictions_comparison', f'comparison_out{output_step}.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"  ‚úì ƒê√£ l∆∞u: {output_file}")


def plot_comparison_by_model(results_dir, model, output_steps, output_dir, num_samples=3):
    """
    V·∫Ω bi·ªÉu ƒë·ªì so s√°nh predictions c·ªßa c√πng model v·ªõi c√°c output_steps kh√°c nhau

    Args:
        results_dir: Th∆∞ m·ª•c k·∫øt qu·∫£
        model: Model c·∫ßn so s√°nh
        output_steps: Danh s√°ch output_steps
        output_dir: Th∆∞ m·ª•c output
        num_samples: S·ªë samples ƒë·ªÉ v·∫Ω
    """
    model_names = {'conv1d_gru': 'Conv1D-GRU-ResNet', 'gru': 'GRU', 'conv1d': 'Conv1D'}
    print(f"\nüìä ƒêang v·∫Ω comparison cho model={model}...")

    # Load predictions cho t·∫•t c·∫£ output_steps
    predictions_data = {}

    for out_step in output_steps:
        result = regenerate_predictions(results_dir, out_step, model)
        if result is not None:
            y_true, y_pred = result
            predictions_data[out_step] = {
                'y_true': y_true,
                'y_pred': y_pred
            }
            print(f"  ‚úì Loaded output_step={out_step}")

    if not predictions_data:
        print(f"  ‚ö†Ô∏è  Kh√¥ng c√≥ predictions cho model={model}")
        return

    # V·∫Ω bi·ªÉu ƒë·ªì
    num_output_steps = len(predictions_data)
    fig, axes = plt.subplots(num_samples, num_output_steps, figsize=(4*num_output_steps, 3*num_samples))

    if num_samples == 1:
        axes = axes.reshape(1, -1)
    if num_output_steps == 1:
        axes = axes.reshape(-1, 1)

    for sample_idx in range(num_samples):
        for out_idx, (out_step, data) in enumerate(predictions_data.items()):
            ax = axes[sample_idx, out_idx]

            # Get data (ch·ªâ l·∫•y s·ªë timesteps = output_step)
            y_true_sample = data['y_true'][sample_idx][:out_step]
            y_pred_sample = data['y_pred'][sample_idx][:out_step]

            # Plot
            time_steps = range(len(y_true_sample))

            ax.plot(time_steps, y_true_sample, 'o-', linewidth=2, markersize=6,
                   label='True', color='black', alpha=0.7)
            ax.plot(time_steps, y_pred_sample, 's-', linewidth=2, markersize=6,
                   label='Predicted', color='#e74c3c')

            # Calculate error
            mae = np.mean(np.abs(y_true_sample - y_pred_sample))

            ax.set_title(f'Out={out_step} steps\nSample {sample_idx+1} (MAE={mae:.6f})',
                        fontsize=11, fontweight='bold')
            ax.set_xlabel('Timestep', fontsize=10)
            ax.set_ylabel('Value', fontsize=10)
            ax.legend(fontsize=9, loc='best')
            ax.grid(True, alpha=0.3, linestyle='--')

    model_display_name = model_names.get(model, model.upper().replace("_", "-"))
    plt.suptitle(f'Prediction Comparison - {model_display_name}',
                fontsize=14, fontweight='bold', y=1.00)
    plt.tight_layout()

    # Save
    os.makedirs(os.path.join(output_dir, 'predictions_comparison'), exist_ok=True)
    output_file = os.path.join(output_dir, 'predictions_comparison', f'comparison_{model}.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"  ‚úì ƒê√£ l∆∞u: {output_file}")


def plot_overlay_comparison(results_dir, output_step, models, output_dir, num_samples=10):
    """
    V·∫Ω bi·ªÉu ƒë·ªì overlay: C·∫£ 3 models tr√™n c√πng m·ªôt subplot
    Ch·ªçn 10 samples c√≥ MSE th·∫•p nh·∫•t t·ª´ model Conv1D-GRU-ResNet

    Args:
        results_dir: Th∆∞ m·ª•c k·∫øt qu·∫£
        output_step: Output step c·∫ßn so s√°nh
        models: Danh s√°ch models
        output_dir: Th∆∞ m·ª•c output
        num_samples: S·ªë samples ƒë·ªÉ v·∫Ω (default: 10)
    """
    print(f"\nüìä ƒêang v·∫Ω overlay comparison cho output_step={output_step}...")

    # Load predictions cho t·∫•t c·∫£ models (to√†n b·ªô test set ƒë·ªÉ t√¨m best samples)
    predictions_data_full = {}

    for model in models:
        result = regenerate_predictions_full(results_dir, output_step, model)
        if result is not None:
            y_true, y_pred = result
            predictions_data_full[model] = {
                'y_true': y_true,
                'y_pred': y_pred
            }
            print(f"  ‚úì Loaded {model}: {len(y_true)} samples")

    if not predictions_data_full:
        print(f"  ‚ö†Ô∏è  Kh√¥ng c√≥ predictions cho output_step={output_step}")
        return

    # T√¨m 10 samples c√≥ MSE th·∫•p nh·∫•t t·ª´ Conv1D-GRU-ResNet
    conv1d_gru_key = None
    for key in predictions_data_full.keys():
        if 'conv1d_gru' in key.lower():
            conv1d_gru_key = key
            break

    if conv1d_gru_key is None:
        print(f"  ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y Conv1D-GRU-ResNet model")
        # Fallback: use first num_samples
        best_indices = list(range(min(num_samples, len(list(predictions_data_full.values())[0]['y_true']))))
    else:
        # T√≠nh MSE cho t·ª´ng sample
        y_true = predictions_data_full[conv1d_gru_key]['y_true']
        y_pred = predictions_data_full[conv1d_gru_key]['y_pred']

        mse_per_sample = []
        for i in range(len(y_true)):
            mse = np.mean((y_true[i] - y_pred[i]) ** 2)
            mse_per_sample.append((i, mse))

        # Sort by MSE v√† l·∫•y top num_samples
        mse_per_sample.sort(key=lambda x: x[1])
        best_indices = [idx for idx, _ in mse_per_sample[:num_samples]]

        print(f"  ‚úì ƒê√£ ch·ªçn {num_samples} samples t·ªët nh·∫•t (MSE th·∫•p nh·∫•t)")
        print(f"    Best MSE range: {mse_per_sample[0][1]:.6f} - {mse_per_sample[num_samples-1][1]:.6f}")

    # Extract predictions cho best samples
    predictions_data = {}
    for model, data in predictions_data_full.items():
        predictions_data[model] = {
            'y_true': data['y_true'][best_indices],
            'y_pred': data['y_pred'][best_indices]
        }

    # Load past data (input) t·ª´ cache cho best indices
    try:
        from data_cache import DataCache
        from config import Config
        from data_loader import VibrationDataLoader
        from data_preprocessing import DataPreprocessor

        cache = DataCache()
        cache_key = cache.get_cache_key(
            sensor_idx=0,
            output_steps=output_step,
            add_noise=True,
            input_steps=50
        )

        if cache.cache_exists(cache_key):
            data_dict = cache.load_cache(cache_key)
        else:
            # T·∫°o cache n·∫øu ch∆∞a c√≥
            mat_file = Config.get_mat_file_path()
            data_loader = VibrationDataLoader(mat_file)
            full_data = data_loader.load_mat_file()
            raw_data = data_loader.get_sensor_data(sensor_idx=0)
            preprocessor = DataPreprocessor(input_steps=50, output_steps=output_step, add_noise=True)
            data_dict = preprocessor.prepare_data(raw_data)
            cache.save_cache(data_dict, cache_key)

        X_test = data_dict['X_test']
        preprocessor = data_dict['preprocessor']

        # Denormalize past data cho best indices
        past_data_list = []
        for idx in best_indices:
            past_denorm = preprocessor.inverse_transform(X_test[idx].reshape(1, -1))
            past_data_list.append(past_denorm.flatten())
    except Exception as e:
        print(f"  ‚ö†Ô∏è  Kh√¥ng load ƒë∆∞·ª£c past data: {e}")
        past_data_list = None

    # Colors cho t·ª´ng model
    colors = {
        'conv1d_gru': '#2ecc71',  # Xanh l√° - Conv1D-GRU-ResNet
        'gru': '#3498db',          # Xanh d∆∞∆°ng - GRU
        'conv1d': '#e74c3c'        # ƒê·ªè - Conv1D
    }

    # Model name mapping
    model_names = {
        'conv1d_gru': 'Conv1D-GRU-ResNet',
        'gru': 'GRU',
        'conv1d': 'Conv1D'
    }

    # T·∫°o subplots (num_samples rows, 1 column)
    fig, axes = plt.subplots(num_samples, 1, figsize=(14, 4*num_samples))

    if num_samples == 1:
        axes = [axes]

    # Get y_true reference (same for all models)
    y_true_ref = list(predictions_data.values())[0]['y_true']

    for sample_idx in range(num_samples):
        ax = axes[sample_idx]

        # Plot past data n·∫øu c√≥
        if past_data_list is not None and sample_idx < len(past_data_list):
            past_data = past_data_list[sample_idx]
            past_timesteps = range(len(past_data))
            ax.plot(past_timesteps, past_data, 'o-', linewidth=2, markersize=4,
                   label='Past Data (Input)', color='green', alpha=0.6)

        # Plot actual future
        y_true_sample = y_true_ref[sample_idx]
        future_start = len(past_data_list[sample_idx]) if past_data_list else 0
        future_timesteps = range(future_start, future_start + len(y_true_sample))

        ax.plot(future_timesteps, y_true_sample, 'o-', linewidth=2.5, markersize=6,
               label='Actual Future', color='blue', alpha=0.8, zorder=10)

        # Plot predictions t·ª´ t·∫•t c·∫£ models
        for model, data in predictions_data.items():
            y_pred_sample = data['y_pred'][sample_idx]

            model_display_name = model_names.get(model, model.upper().replace("_", "-"))
            ax.plot(future_timesteps, y_pred_sample, 's--', linewidth=2, markersize=5,
                   label=f'Predicted ({model_display_name})',
                   color=colors.get(model, '#95a5a6'), alpha=0.7)

        # Formatting
        ax.set_xlabel('Time Step', fontsize=11, fontweight='bold')
        ax.set_ylabel('Value', fontsize=11, fontweight='bold')
        ax.set_title(f'Sample {sample_idx+1} - Output Steps = {output_step}',
                    fontsize=12, fontweight='bold')
        ax.legend(fontsize=10, loc='best', framealpha=0.9)
        ax.grid(True, alpha=0.3, linestyle='--')
        ax.axhline(y=0, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)

    plt.suptitle(f'Prediction Comparison (Overlay) - Output Steps = {output_step}',
                fontsize=14, fontweight='bold', y=0.995)
    plt.tight_layout()

    # Save
    os.makedirs(os.path.join(output_dir, 'predictions_comparison'), exist_ok=True)
    output_file = os.path.join(output_dir, 'predictions_comparison', f'overlay_out{output_step}.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"  ‚úì ƒê√£ l∆∞u: {output_file}")


def plot_all_combinations_grid(results_dir, models, output_steps, output_dir, sample_idx=0):
    """
    V·∫Ω grid t·ªïng quan t·∫•t c·∫£ combinations (models √ó output_steps)

    Args:
        results_dir: Th∆∞ m·ª•c k·∫øt qu·∫£
        models: Danh s√°ch models
        output_steps: Danh s√°ch output_steps
        output_dir: Th∆∞ m·ª•c output
        sample_idx: Index c·ªßa sample c·∫ßn v·∫Ω
    """
    print(f"\nüìä ƒêang v·∫Ω grid t·ªïng quan (sample {sample_idx})...")

    num_models = len(models)
    num_steps = len(output_steps)

    fig, axes = plt.subplots(num_models, num_steps, figsize=(3.5*num_steps, 3*num_models))

    if num_models == 1:
        axes = axes.reshape(1, -1)
    if num_steps == 1:
        axes = axes.reshape(-1, 1)

    colors = {'conv1d_gru': '#2ecc71', 'gru': '#3498db', 'conv1d': '#e74c3c'}
    model_names = {'conv1d_gru': 'Conv1D-GRU-ResNet', 'gru': 'GRU', 'conv1d': 'Conv1D'}

    for model_idx, model in enumerate(models):
        for step_idx, out_step in enumerate(output_steps):
            ax = axes[model_idx, step_idx]

            # Load predictions
            result = regenerate_predictions(results_dir, out_step, model)

            if result is None:
                ax.text(0.5, 0.5, 'No Data', ha='center', va='center', fontsize=12)
                ax.set_title(f'{model}\nout={out_step}', fontsize=10)
                continue

            y_true, y_pred = result
            y_true_sample = y_true[sample_idx][:out_step]
            y_pred_sample = y_pred[sample_idx][:out_step]

            # Plot
            time_steps = range(len(y_true_sample))

            ax.plot(time_steps, y_true_sample, 'o-', linewidth=1.5, markersize=4,
                   label='True', color='black', alpha=0.7)
            ax.plot(time_steps, y_pred_sample, 's-', linewidth=1.5, markersize=4,
                   label='Pred', color=colors.get(model, '#95a5a6'))

            # Calculate MAE
            mae = np.mean(np.abs(y_true_sample - y_pred_sample))

            # Title
            model_display_name = model_names.get(model, model.upper().replace("_", "-"))
            if step_idx == 0:
                title = f'{model_display_name}\nout={out_step}\nMAE={mae:.4f}'
            else:
                title = f'out={out_step}\nMAE={mae:.4f}'

            ax.set_title(title, fontsize=9, fontweight='bold')

            if model_idx == num_models - 1:
                ax.set_xlabel('Step', fontsize=8)
            if step_idx == 0:
                ax.set_ylabel('Value', fontsize=8)

            if model_idx == 0 and step_idx == 0:
                ax.legend(fontsize=7, loc='best')

            ax.grid(True, alpha=0.2, linestyle='--')
            ax.tick_params(labelsize=7)

    plt.suptitle(f'Predictions Grid - All Combinations (Sample {sample_idx+1})',
                fontsize=15, fontweight='bold')
    plt.tight_layout()

    # Save
    os.makedirs(os.path.join(output_dir, 'predictions_comparison'), exist_ok=True)
    output_file = os.path.join(output_dir, 'predictions_comparison', f'grid_sample{sample_idx}.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"  ‚úì ƒê√£ l∆∞u: {output_file}")


def main():
    """Main function"""
    args = parse_args()

    print("=" * 100)
    print("  V·∫º BI·ªÇU ƒê·ªí SO S√ÅNH PREDICTIONS")
    print("=" * 100)

    # Ki·ªÉm tra results_dir
    if not os.path.exists(args.results_dir):
        print(f"\n‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {args.results_dir}")
        sys.exit(1)

    # T·∫°o output directory
    os.makedirs(args.output_dir, exist_ok=True)

    # Detect models v√† output_steps
    models = []
    output_steps = []

    for folder in os.listdir(args.results_dir):
        folder_path = os.path.join(args.results_dir, folder)
        if not os.path.isdir(folder_path):
            continue

        # Check if folder name is number (output_step)
        try:
            out_step = int(folder)
            output_steps.append(out_step)

            # Get models in this folder
            for model_folder in os.listdir(folder_path):
                if os.path.isdir(os.path.join(folder_path, model_folder)):
                    if model_folder not in models:
                        models.append(model_folder)
        except ValueError:
            continue

    models = sorted(models)
    output_steps = sorted(output_steps)

    print(f"\nƒê√£ ph√°t hi·ªán:")
    print(f"  Models: {models}")
    print(f"  Output steps: {output_steps}")

    if not models or not output_steps:
        print("\n‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu!")
        sys.exit(1)

    # V·∫Ω c√°c bi·ªÉu ƒë·ªì
    print("\n" + "=" * 100)
    print("  ƒêANG T·∫†O VISUALIZATIONS")
    print("=" * 100)

    # 1. Overlay comparison (C·∫¢ 3 models tr√™n c√πng subplot - KHUY√äN D√ôNG)
    print("\n1. Overlay Comparison (3 models on same plot):")
    for out_step in output_steps:
        plot_overlay_comparison(args.results_dir, out_step, models,
                               args.output_dir, num_samples=args.num_samples)

    # 2. Comparison by output_step (so s√°nh models cho m·ªói output_step - 3 subplots)
    print("\n2. Comparison by Output Step (separate subplots):")
    for out_step in output_steps:
        plot_comparison_by_output_step(args.results_dir, out_step, models,
                                      args.output_dir, num_samples=args.num_samples)

    # 3. Comparison by model (so s√°nh output_steps cho m·ªói model)
    print("\n3. Comparison by Model:")
    for model in models:
        plot_comparison_by_model(args.results_dir, model, output_steps,
                                args.output_dir, num_samples=args.num_samples)

    # 4. Grid t·ªïng quan
    print("\n4. Overview Grid:")
    for sample_idx in range(min(3, args.num_samples)):
        plot_all_combinations_grid(args.results_dir, models, output_steps,
                                   args.output_dir, sample_idx=sample_idx)

    print("\n" + "=" * 100)
    print("‚úÖ HO√ÄN TH√ÄNH!")
    print("=" * 100)
    print(f"\nüìÅ K·∫øt qu·∫£ l∆∞u t·∫°i: {args.output_dir}/predictions_comparison/")
    print("\nC√°c files ƒë√£ t·∫°o:")
    print("  üåü overlay_out{5,10,15,20,30,40}.png     # Overlay 3 models (KHUY√äN XEM)")
    print("  - comparison_out{5,10,15,20,30,40}.png  # So s√°nh models (3 subplots)")
    print("  - comparison_{model}.png                 # So s√°nh output_steps theo model")
    print("  - grid_sample{0,1,2}.png                 # Grid t·ªïng quan")
    print("=" * 100)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interrupted by user!")
        sys.exit(130)
    except Exception as e:
        print(f"\n\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
