## ğŸ“Š HÆ¯á»šNG DáºªN SO SÃNH MODELS Vá»šI CÃC OUTPUT_STEPS

HÆ°á»›ng dáº«n nÃ y giÃºp báº¡n so sÃ¡nh performance cá»§a 3 models (Conv1D-GRU, GRU, Conv1D) vá»›i cÃ¡c output_steps khÃ¡c nhau (5, 10, 15, 20, 30, 40).

## ğŸ¯ Má»¥c Ä‘Ã­ch

1. **Train táº¥t cáº£ combinations** cá»§a models Ã— output_steps (3 Ã— 6 = 18 combinations)
2. **Thu tháº­p metrics** (RMSE, MAE, RÂ²) tá»« táº¥t cáº£ experiments
3. **Visualize** so sÃ¡nh performance
4. **TÃ¬m best configuration** cho tá»«ng metric

## ğŸ“‹ Quy trÃ¬nh

### BÆ°á»›c 1: Train táº¥t cáº£ combinations

```bash
conda activate tf
python compare_output_steps.py
```

**Script nÃ y sáº½:**
- Train 3 models: `conv1d_gru`, `gru`, `conv1d`
- Vá»›i 6 output_steps: `5, 10, 15, 20, 30, 40`
- Tá»•ng cá»™ng: **18 training runs**
- Má»—i model train vá»›i **1000 epochs**, batch_size=64
- Káº¿t quáº£ lÆ°u vÃ o: `results_comparison/{model}_out{step}/`

**VÃ­ dá»¥ cáº¥u trÃºc output:**
```
results_comparison/
â”œâ”€â”€ conv1d_gru_out5/
â”‚   â”œâ”€â”€ model_saved.keras
â”‚   â”œâ”€â”€ metrics.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ conv1d_gru_out10/
â”œâ”€â”€ conv1d_gru_out15/
â”œâ”€â”€ ...
â”œâ”€â”€ gru_out5/
â”œâ”€â”€ gru_out10/
â””â”€â”€ ...
```

**Thá»i gian Æ°á»›c tÃ­nh:**
- Má»—i training: ~15-30 phÃºt (tÃ¹y hardware)
- **Tá»•ng:** ~5-10 giá» cho táº¥t cáº£ 18 combinations

**ğŸ’¡ Tips:**
- Cache data sáº½ tá»± Ä‘á»™ng tÃ¡i sá»­ dá»¥ng (chá»‰ preprocess 6 láº§n thay vÃ¬ 18 láº§n!)
- CÃ³ thá»ƒ cháº¡y qua Ä‘Ãªm
- DÃ¹ng `Ctrl+C` Ä‘á»ƒ dá»«ng náº¿u cáº§n

### BÆ°á»›c 2: PhÃ¢n tÃ­ch káº¿t quáº£

```bash
python analyze_results.py --results_dir results_comparison --output_dir analysis
```

**Script nÃ y sáº½ táº¡o:**

1. **`comparison_table.csv`** - Báº£ng so sÃ¡nh Ä‘áº§y Ä‘á»§
   ```
   model,output_step,dataset,rmse,mae,r2
   conv1d_gru,5,Test,0.001234,0.000987,0.9756
   conv1d_gru,10,Test,0.001456,0.001123,0.9634
   ...
   ```

2. **`metrics_vs_output_steps.png`** - Biá»ƒu Ä‘á»“ line charts
   - 3 subplots: RÂ², RMSE, MAE
   - X-axis: Output steps
   - Lines: 3 models
   - Dá»… nhÃ¬n trend khi output_steps tÄƒng

3. **`heatmaps.png`** - Heatmaps
   - 3 heatmaps: RÂ², RMSE, MAE
   - Rows: Models
   - Columns: Output steps
   - Color: Performance (xanh = tá»‘t, Ä‘á» = xáº¥u)

4. **`best_configurations.csv`** - Best configs
   ```
   Metric,Model,Output Steps,Value,RMSE,MAE
   Best RÂ²,conv1d_gru,5,0.9756,0.001234,0.000987
   Best RMSE,conv1d_gru,5,0.001234,0.001234,0.000987
   Best MAE,gru,10,0.000950,0.001345,0.000950
   ```

5. **`summary_report.txt`** - BÃ¡o cÃ¡o text chi tiáº¿t

**Thá»i gian:** ~30 giÃ¢y

## ğŸ“Š Káº¿t quáº£ mong Ä‘á»£i

### Trend dá»± kiáº¿n:

1. **Output steps cÃ ng nhá» â†’ Performance cÃ ng tá»‘t**
   - Output_steps=5: RÂ² cao nháº¥t (~0.97)
   - Output_steps=40: RÂ² tháº¥p hÆ¡n (~0.85-0.90)

2. **Conv1D-GRU thÆ°á»ng tá»‘t nháº¥t**
   - CÃ³ ResNet (skip connection)
   - Tá»‘t hÆ¡n GRU vÃ  Conv1D thuáº§n

3. **Trade-off giá»¯a horizon vÃ  accuracy**
   - Short-term (5 steps): Ráº¥t accurate
   - Long-term (40 steps): Ãt accurate hÆ¡n nhÆ°ng váº«n cháº¥p nháº­n Ä‘Æ°á»£c

## ğŸ¯ Use Cases

### Use Case 1: TÃ¬m best model cho short-term forecasting

```bash
# 1. Train
python compare_output_steps.py

# 2. PhÃ¢n tÃ­ch
python analyze_results.py

# 3. Xem best_configurations.csv
cat analysis/best_configurations.csv
```

â†’ Chá»n model cÃ³ Best RÂ² vá»›i output_steps nhá» (5 hoáº·c 10)

### Use Case 2: TÃ¬m model tá»‘t nháº¥t cho long-term forecasting

â†’ Xem performance á»Ÿ output_steps=30 hoáº·c 40 trong heatmaps

### Use Case 3: Tháº¥y trade-off giá»¯a models

â†’ Xem line charts: Má»™t sá»‘ models giáº£m performance nhanh hÆ¡n khi output_steps tÄƒng

## ğŸ”§ TÃ¹y chá»‰nh

### Thay Ä‘á»•i epochs hoáº·c batch_size

Chá»‰nh sá»­a `compare_output_steps.py`:

```python
EPOCHS = 500        # Giáº£m náº¿u muá»‘n nhanh hÆ¡n
BATCH_SIZE = 128    # TÄƒng náº¿u GPU máº¡nh
```

### Chá»‰ train má»™t sá»‘ output_steps

```python
OUTPUT_STEPS = [5, 10, 20]  # Thay vÃ¬ [5, 10, 15, 20, 30, 40]
```

### Chá»‰ train má»™t sá»‘ models

```python
MODELS = ['conv1d_gru', 'gru']  # Bá» conv1d
```

### Train riÃªng láº» tá»«ng combination

```bash
# Train má»™t combination cá»¥ thá»ƒ
python main.py --models conv1d_gru --output_steps 10 --output_dir results_comparison/conv1d_gru_out10
```

## ğŸ“ˆ VÃ­ dá»¥ káº¿t quáº£ thá»±c táº¿

### Báº£ng so sÃ¡nh (Test Set)

| Model | Out Steps | RMSE | MAE | RÂ² |
|-------|-----------|------|-----|-----|
| **conv1d_gru** | **5** | **0.001010** | **0.000745** | **0.9755** |
| conv1d_gru | 10 | 0.001234 | 0.000892 | 0.9634 |
| conv1d_gru | 20 | 0.001567 | 0.001123 | 0.9456 |
| gru | 5 | 0.001134 | 0.000823 | 0.9630 |
| gru | 10 | 0.001345 | 0.000950 | 0.9512 |
| conv1d | 5 | 0.002301 | 0.001634 | 0.8674 |

### Best Configurations

- **Best RÂ²:** Conv1D-GRU vá»›i output_steps=5 (RÂ²=0.9755)
- **Best RMSE:** Conv1D-GRU vá»›i output_steps=5 (RMSE=0.001010)
- **Best MAE:** Conv1D-GRU vá»›i output_steps=5 (MAE=0.000745)

### Key Insights

1. **Conv1D-GRU is the winner** cho táº¥t cáº£ metrics vÃ  output_steps
2. **Performance degrades ~10-15%** khi tÄƒng tá»« 5â†’40 steps
3. **GRU lÃ  runner-up** tá»‘t, gáº§n báº±ng Conv1D-GRU
4. **Conv1D thuáº§n** kÃ©m hÆ¡n nhiá»u (~10% so vá»›i Conv1D-GRU)

## ğŸš€ Quick Start

```bash
# Full workflow
conda activate tf

# Step 1: Train (5-10 giá»)
python compare_output_steps.py

# Step 2: Analyze (30 giÃ¢y)
python analyze_results.py

# Step 3: Xem káº¿t quáº£
cat analysis/summary_report.txt
open analysis/metrics_vs_output_steps.png
open analysis/heatmaps.png
```

## ğŸ“ File Structure

```
4_Code/
â”œâ”€â”€ compare_output_steps.py      # Script train táº¥t cáº£ combinations
â”œâ”€â”€ analyze_results.py            # Script phÃ¢n tÃ­ch káº¿t quáº£
â”œâ”€â”€ COMPARISON_GUIDE.md           # HÆ°á»›ng dáº«n nÃ y
â”‚
â”œâ”€â”€ results_comparison/           # Káº¿t quáº£ training (18 folders)
â”‚   â”œâ”€â”€ conv1d_gru_out5/
â”‚   â”œâ”€â”€ conv1d_gru_out10/
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ analysis/                     # Káº¿t quáº£ phÃ¢n tÃ­ch
    â”œâ”€â”€ comparison_table.csv
    â”œâ”€â”€ metrics_vs_output_steps.png
    â”œâ”€â”€ heatmaps.png
    â”œâ”€â”€ best_configurations.csv
    â””â”€â”€ summary_report.txt
```

## âš ï¸ LÆ°u Ã½

1. **Äáº£m báº£o Ä‘á»§ dung lÆ°á»£ng:** ~500MB cho 18 models
2. **Training máº¥t nhiá»u thá»i gian:** 5-10 giá»
3. **Sá»­ dá»¥ng GPU:** Náº¿u cÃ³, sáº½ nhanh hÆ¡n nhiá»u
4. **Cache Ä‘Æ°á»£c sá»­ dá»¥ng:** Tiáº¿t kiá»‡m thá»i gian preprocessing
5. **CÃ³ thá»ƒ interrupt vÃ  resume:** CÃ¡c models Ä‘Ã£ train sáº½ Ä‘Æ°á»£c giá»¯ nguyÃªn

## ğŸ’¡ Pro Tips

1. **Cháº¡y overnight:** Äá»ƒ train táº¥t cáº£ 18 combinations
2. **Monitor progress:** Kiá»ƒm tra folder `results_comparison/` xem Ä‘Ã£ cÃ³ bao nhiÃªu models
3. **Resume náº¿u bá»‹ interrupt:** Script tá»± Ä‘á»™ng skip models Ä‘Ã£ train (kiá»ƒm tra folder tá»“n táº¡i)
4. **Compare vá»›i baseline:** Cháº¡y thÃªm baseline models (linear, xgboost, lightgbm) Ä‘á»ƒ so sÃ¡nh

---

**Happy Comparing! ğŸ“Š**
